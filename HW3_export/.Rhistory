knitr::opts_chunk$set(echo = TRUE, results = "hide", fig.width=6, fig.height=4)
if(!require('pacman')) {
install.packages('pacman')
}
pacman::p_load(pROC, leaps, car, tidyverse, mapproj, caret)
knitr::opts_chunk$set(fig.height=4, fig.width=6, warning = F)
# constants for homework assignments
hw_num <- 3
hw_due_date <- "22 October, 2017"
# Notice that we hide the code and the results here
# Using `include=F` in the chunk declaration
hd_data <- read.csv("Framingham.dat")
str(hd_data)
### Renames, setting the variables with correct natures...
names(hd_data)[1] <- "HD"
hd_data$HD <- as.factor(hd_data$HD)
hd_data$SEX <- as.factor(hd_data$SEX)
str(hd_data)
#tail(hd_data, 1)    # The last row is for prediction
hd_data.new <- hd_data[1407,] # The female whose HD will be predicted.
hd_data <- hd_data[-1407,]  # take out the last row
hd_data.f <- na.omit(hd_data)
# Notice that we hide the code and the results here
# Using `include=F` in the chunk declaration
hd_data <- read.csv("Framingham.dat")
str(hd_data)
### Renames, setting the variables with correct natures...
names(hd_data)[1] <- "HD"
hd_data$HD <- as.factor(hd_data$HD)
hd_data$SEX <- as.factor(hd_data$SEX)
str(hd_data)
#tail(hd_data, 1)    # The last row is for prediction
hd_data.new <- hd_data[1407,] # The female whose HD will be predicted.
hd_data <- hd_data[-1407,]  # take out the last row
hd_data.f <- na.omit(hd_data)
str(hd_data)
names(hd_data)[1] <- "HD"
hd_data$HD <- as.factor(hd_data$HD)
str(hd_data)
hd_data$HD <- as.factor(hd_data$HD)
hd_data$SEX <- as.factor(hd_data$SEX)
str(hd_data)
tail(hd_data, 1)    # The last row is for prediction
tail(hd_data, 10)    # The last row is for prediction
tail(hd_data, 50)    # The last row is for prediction
tail(hd_data, 1)    # The last row is for prediction
hd_data.new <- hd_data[1407,] # The female whose HD will be predicted.
hd_data.new
hd_data.new <- hd_data[1407,] # The female whose HD will be predicted.
hd_data.new
hd_data.new <- hd_data[,1407] # The female whose HD will be predicted.
hd_data.new <- hd_data[1407,] # The female whose HD will be predicted.
hd_data.new
hd_data <- hd_data[-1407,]  # take out the last row
hd_data.f <- na.omit(hd_data)
table(hd_data$HD) # HD: 311 of "0" and 1095 "1"
str(hd_data)
tail(hd_data, 1)    # The last row is for prediction
hd_data.new
summary(hd_data.f)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
knitr::opts_chunk$set(echo = TRUE)
frame_data <- read.csv("Framingham,dat", sep=",", header = T, as.is = T)
frame_data <- read.csv("Framingham.dat", sep=",", header = T, as.is = T)
fram_data <- read.csv("Framingham.dat", sep=",", header = T, as.is = T)
fram_data
summary(fram_data)
str(fram_data)
names(fram_data)
str(fram_data)
names(fram_data) # column names
fram_data$AGE
hd_data <- read.csv("Framingham.dat")
str(hd_data)
names(hd_data)[1] <- "HD"
names(hd_data)
hd_data$HD <- as.factor(hd_data$HD)
hd_data$SEX <- as.factor(hd_data$SEX)
str(hd_data)
hd_data.new <- hd_data[1407,] # The female whose HD will be predicted.
hd_data.new
hd_data <- hd_data[-1407,]  # take out the last row
hd_data.f <- na.omit(hd_data)
table(hd_data$HD) # HD: 311 of "0" and 1095 "1"
summary(hd_data.f)
tail(fram_data, 10)
sum(is.na(fram_data))
hd_data.f <- na.omit(hd_data)
sum(is.na((hd_data.f)))
names(fram_data) # column names
table(hd_data.f$SEX)
hd_data.f$SEX <- as.factor(hd_data.f$SEX)
table(hd_data.f$SEX)
hd_data.f$SEX
tapply(hd_data$SBP, hd_data$HD, mean)
tapply(hd_data$SBP, hd_data$HD, mean)
fit1 <- glm(HD~SBP, hd_data.f, family=binomial)
summary(fit1)
fit1.1 <- glm(HD~SBP + AGE, hd_data.f, family=binomial)
summary(fit1.1)
fit1.2 <- glm(HD~SBP + SEX, hd_data.f, family=binomial)
summary(fit1.2)
fit1.3 <- glm(HD~SBP + DBP, hd_data.f, family=binomial)
summary(fit1.3)
fit1.4 <- glm(HD~SBP + CHOL, hd_data.f, family=binomial)
summary(fit1.4)
fit1.5 <- glm(HD~SBP + DBP, hd_data.f, family=binomial)
summary(fit1.5)
fit1.6 <- glm(HD~SBP + FRW, hd_data.f, family=binomial)
summary(fit1.6)
fit1.7 <- glm(HD~SBP + CIG, hd_data.f, family=binomial)
summary(fit1.7)
library(xtable)
install.packages(xtable)
install.packages("xtable"")
library(xtable)
options(xtable.comment = FALSE)
fit2 <- glm(HD~SBP + SEX, hd_data.f, family=binomial)
xtable(fit2)
install.packages("xtable")
library(xtable)
install.packages("xtable")
library(xtable)
options(xtable.comment = FALSE)
fit2 <- glm(HD~SBP + SEX, hd_data.f, family=binomial)
xtable(fit2)
knitr::opts_chunk$set(echo = TRUE, results = "hide", fig.width=6, fig.height=4)
if(!require('pacman')) {
install.packages('pacman')
}
pacman::p_load(bestglm, glmnet, leaps, car, tidyverse, mapproj)
fram_data <- read.csv("Framingham.dat", sep=",", header=T, as.is=T)
fram_data <- read.csv("Framingham.dat", sep=",", header=T, as.is=T)
str(fram_data)
names(fram_data)
summary(fram_data)
fram_data %<>%   # make the following change to the data frame
rename(HD = Heart.Disease.) %>%
mutate(HD = as.factor(HD),
SEX = as.factor(SEX))
str(fram_data)
tail(fram_data, 1)
fram_data.new <- fram_data[1407,]
fram_data <- fram_data[-1407,]
summary(fram_data)
sum(is.na(fram_data))
tapply(fram_data$SBP, fram_data$HD, mean)
plot(fram_data$HD, fram_data$SBP, ylab ="SBP", xlab = "HD")
boxplot(fram_data$SBP~fram_data$HD, ylab ="SBP", xlab = "HD")
plot(fram_data$SBP,
fram_data$HD,
col=fram_data$HD,
xlab = "SBP",
ylab = "HD")
legend("topright",
legend=c("0", "1"),
lty=c(1,1),
lwd=c(2,2),
col=unique(fram_data$HD))
plot(jitter(as.numeric(fram_data$HD), factor=.5) ~ fram_data$SBP,
pch=4,
col=fram_data$HD,
ylab="HD",
xlab="SBP")
legend("topright", legend=c("0", "1"),
lty=c(1,1), lwd=c(2,2), col=unique(fram_data$HD))
stripchart(fram_data$SBP~fram_data$HD, method="jitter",
col=c("black", "red"), pch=4,
ylab="HD", xlab="HB")
legend("topright", legend=c("0", "1"),
lty=c(1,1), lwd=c(2,2), col=unique(fram_data$HD))
set.seed(2)
fram_data[sample(1:1406, 10), c("HD", "SBP")]
fit1 <- glm(HD~SBP, fram_data, family=binomial(logit))
summary(fit1, results=TRUE)
par(mfrow=c(1,1))
plot(fram_data$SBP, fit1$fitted.values, pch=16,
xlab="SBP",
ylab="Prob of P(Y=1|SBP)")
x <- seq(100, 300, by=1)
y <- exp(-3.66+0.0159*x)/(1+exp(-3.66+0.0159*x))
plot(x, y, pch=16, type = "l",
xlab = "SBP",
ylab = "Prob of P(Y=1|SBP)" )
summary(fit1)
confint.default(fit1)
summary(fit1)
pchisq(chi.sq, 1, lower.tail=FALSE)
chi.sq <- 1485.9-1432.8
pchisq(chi.sq, 1, lower.tail=FALSE)
anova(fit1, test="Chisq") #
Anova(fit1)
par(mfrow=c(2,1))
hist(rchisq(10000, 2), freq=FALSE, breaks=20)
hist(rchisq(10000, 20), freq=FALSE, breaks=20)
confint(fit1)
fit1.predict <- predict(fit1, fram_data.new, type="response")
fit1.predict
fram_data.f <- na.omit(fram_data)
fit2 <- glm(HD~., fram_data.f, family=binomial)
summary(fit2)
chi.sq <- 1469-1343
chi.sq  #126
pvalue <- pchisq(chi.sq, 7, lower.tail=FALSE)
pvalue
pvalue <- pchisq(chi.sq, 7, lower.tail=FALSE)
pvalue
fit0 <- glm(HD~1, fram_data.f, family=binomial) # null
anova(fit0, fit2, test="Chisq") #
fit3 <- update(fit2, .~. -CIG -FRW)
summary(fit3)
chi.sq.2 <- fit3$deviance-fit2$deviance
chi.sq.2
pchisq(chi.sq.2, 2, lower.tail=FALSE) # 0.06194729
anova(fit3, fit2, test="Chisq")
summary(fit2)
fit2.1 <- update(fit2, .~. -DBP)
summary(fit2.1)
fit2.2 <- update(fit2.1, .~. -FRW)
summary(fit2.2)
fit2.3 <- update(fit2.2, .~. -CIG)
summary(fit2.3)
fit2.3.predict <- predict(fit2.3, fram_data.new, type="response")
fit2.3.predict
predict(fit1, fram_data.new, type="response") #
fit2 <- glm(HD~., fram_data.f, family=binomial)
summary(fit2)
Xy <- model.matrix(HD ~.+0, fram_data.f)
Xy <- data.frame(Xy, fram_data.f$HD)
str(Xy)
fit.all <- bestglm(Xy, family = binomial, method = "exhaustive", IC="AIC", nvmax = 10)
names(fit.all)
fit.all$BestModels
summary(fit.all$BestModel)
summary(glm(HD~AGE+SEX+SBP+CHOL+FRW+CIG, family=binomial, data=fram_data.f))
Anova(glm(HD ~ AGE + SBP + SEX + SBP*SEX + AGE * SEX, fram_data, family = binomial))
knitr::opts_chunk$set(echo = TRUE, results = "hide", fig.width=6, fig.height=4)
if(!require('pacman')) {
install.packages('pacman')
}
pacman::p_load(pROC, leaps, car, tidyverse, mapproj, caret)
data <- read.table("Framingham.dat", sep=",", header=T, as.is=T)
#Wald Test/Intervals
summary(fit2)
confint.default(fit2)
#pval for SEXMALE = 1.02e-10
#CI's for SEXMALE = [0.62949139 1.17734896]
#Added variable is significant at the 0.01 level
#Chi-Squared Test
anova(fit2, test="Chisq")
#pval for SEXMALE = 3.828e-11
#Added variable is significant at the 0.01 level
names(hd_data.f)
fit.full <- glm(HD ~ SBP + SEX + AGE + DBP + CHOL + FRW + CIG, hd_data.f, family=binomial)
summary(fit.full)
fit.sans.BDP <- glm(HD ~ SBP + AGE + SEX + CHOL + FRW + CIG, hd_data.f, family=binomial)
summary(fit.sans.BDP)
fit.sans.DBP.FRW <- glm(HD ~ SBP + AGE + SEX + CHOL + CIG, hd_data.f, family=binomial)
summary(fit.sans.DBP.FRW)
fit.sans.DBP.FRW.CIG <- glm(HD ~ SBP + AGE + SEX + CHOL, hd_data.f, family=binomial)
summary(fit.sans.DBP.FRW.CIG)
fit.bw <- glm(HD ~ SBP + AGE + SEX + CHOL, hd_data.f, family=binomial)
summary(fit.bw)
Xy <- model.matrix(HD ~.+0, hd_data.f)
Xy <- data.frame(Xy, hd_data.f$HD)
fit.exh <- bestglm(Xy, family = binomial, method = "exhaustive", IC="AIC", nvmax = 10)
fit.exh$BestModels
fit.exh$BestModel
fit.exh <- glm(HD ~ SBP + AGE + SEX + CHOL + FRW + CIG, hd_data.f, family=binomial)
summary(fit.exh)
AGE <- 50
SEX <- 'FEMALE'
SBP <- 110
DBP <- 80
CHOL <- 180
FRW <- 105
CIG <- 0
liz <- data.frame(AGE, SEX, SBP, DBP, CHOL, FRW, CIG)
fit.exh.predict <- predict(fit.exh, liz, type="response")
fit.exh.predict
fit1.roc <- roc(hd_data.f$HD, fit1$fitted, plot=T, col="blue")
# Select thresholds where FP rate or 1-specificity is < 0.1
var1 <- fit1.roc$thresholds[1-fit1.roc$specificities < 0.1]
fit1.roc <- roc(hd_data.f$HD, fit1$fitted, plot=T, col="blue")
fit1.roc <- roc(hd_data.f$HD, fit1, plot=T, col="blue")
fit1 <- glm(HD~SBP, hd_data.f, family=binomial)
summary(fit1)
fit1.roc <- roc(hd_data.f$HD, fit1$fitted, plot=T, col="blue")
# Select thresholds where FP rate or 1-specificity is < 0.1
var1 <- fit1.roc$thresholds[1-fit1.roc$specificities < 0.1]
var1
#Out of these values, select which threshold also corresponds to maximum sensitivity or TP rate
var2 <- var1[which.max(fit1.roc$sensitivities)]
var2    #Threshold is P(Yhat = 1) > 0.2982114
#Now, predict the performance of your model
fit1.1 <- rep("0", 1406)   # prediction step 1: set up all values to be "0"
fit1.1[fit1$fitted > var2] <- "1"  # prediction step 2 to get a classifier
fit1.1 <- as.factor(fit1.1) # make this \hat y
fit1.1 <- ifelse(fit1$fitted > var2, "1", "0")  # alternative way to assign \hat y
#Make a confusion table
cm.1 <- table(fit1.1, hd_data.f$HD) # confusion matrix:
cm.1
#FP Rate (1 - specificity)
spec.1 <- cm.1[1,1]/sum(hd_data.f$HD == 0)
FP.1 <- 1-spec.1
FP.1                           #FP Rate = 0.098
#TP Rate (sensitivity)
sens.1 <- cm.1[2,2]/sum(hd_data.f$HD == 1)
sens.1                         #TP Rate = 0.215
fit2.roc <- roc(hd_data.f$HD, fit2$fitted, plot=T, col="blue")
plot(1-fit1.roc$specificities, fit1.roc$sensitivities, col="blue", pch=16, cex=.7,
xlab="False Positive",
ylab="Sensitivity")
points(1-fit2.roc$specificities, fit2.roc$sensitivities, col="red", pch=16, cex=.7)
title("Blue curve is for fit1 and red for fit2")
#For fit1:
fit1.5 <- rep("0", 1406)
fit1.5[fit1$fitted > 0.5] <- "1"
fit1.5 <- as.factor(fit1.5)
cm.1.5 <- table(fit1.5, hd_data$HD)
pos.pred.1.5 <- cm.1.5[2, 2] / (cm.1.5[2, 1] + cm.1.5[2, 2])
neg.pred.1.5 <- cm.1.5[1, 1] / (cm.1.5[1, 1] + cm.1.5[1, 2])
#For fit2:
fit2.5 <- rep("0", 1406)
fit2.5[fit2$fitted > 0.5] <- "1"
fit2.5 <- as.factor(fit2.5)
cm.2.5 <- table(fit2.5, hd_data$HD)
pos.pred.2.5 <- cm.2.5[2, 2] / (cm.2.5[2, 1] + cm.2.5[2, 2])
neg.pred.2.5 <- cm.2.5[1, 1] / (cm.2.5[1, 1] + cm.2.5[1, 2])
#Print out desired variables
cm.1.5
pos.pred.1.5
neg.pred.1.5
cm.2.5
pos.pred.2.5
neg.pred.2.5
fit.exh.pred.bayes <- rep("0", 1406)
fit.exh.pred.bayes[fit.exh$fitted > .091] = "1"
MCE.bayes = (sum(10*(fit.exh.pred.bayes[hd_data$HD == "1"] != "1"))
+ sum(fit.exh.pred.bayes[hd_data$HD == "0"] != "0"))/length(hd_data$HD)
MCE.bayes
#Generate vector with evenly spaced threshold values for P(Y=1)
thresholds <- seq(0,1,length=201)
l <- length(thresholds)
#For each value in the vector, calculate the weighted MCE given a_10/a_01 = 10
mce.vector.10 <- matrix(0,1,201)
for (i in 1:l) {
fit.exh.pred.bayes <- rep("0", 1406)
fit.exh.pred.bayes[fit.exh$fitted > thresholds[i]] = "1"
MCE.bayes = (sum(10*(fit.exh.pred.bayes[hd_data$HD == "1"] != "1"))
+ sum(fit.exh.pred.bayes[hd_data$HD == "0"] != "0"))/length(hd_data$HD)
mce.vector.10[i] <- MCE.bayes
}
#For each value in the vector, calculate the weighted MCE given a_10/a_01 = 1
mce.vector.1 <- matrix(0,1,201)
for (i in 1:l) {
fit.exh.pred.bayes <- rep("0", 1406)
fit.exh.pred.bayes[fit.exh$fitted > thresholds[i]] = "1"
MCE.bayes = (sum(1*(fit.exh.pred.bayes[hd_data$HD == "1"] != "1"))
+ sum(fit.exh.pred.bayes[hd_data$HD == "0"] != "0"))/length(hd_data$HD)
mce.vector.1[i] <- MCE.bayes
}
#Plot both, a_10/a_01 = 10 in blue, a_10,a_01 = 1 in red
plot(thresholds, mce.vector.10, col="blue", pch=16, cex=.7,
xlab="Thresholds for P(Y=1)",
ylab="Weighted MCE",
xlim=c(0, 1),
ylim=c(0, 2.5))
points(thresholds, mce.vector.1, col="red", pch=16, cex=.7)
title("Blue curve for a10/a01 = 10 and red for a10/a01 = 1")
bill.data.test <- read.csv("Bills.subset.test", sep=",", header = T, as.is= T)
bill.data.test <- read.csv("Bills.subset.test.csv", sep=",", header = T, as.is= T)
bill.data.train <- read.csv("Bills.subset.csv")
dim(bill.data.train)
head(bill.data.train)
tail(bill.data.train)
summary(bill.data.train)
